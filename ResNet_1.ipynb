{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oxygen0605/ImageClassification/blob/master/ResNet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj4ebRdWOMpm",
        "colab_type": "text"
      },
      "source": [
        "# Google Colaboratory環境の初期設定\n",
        "\n",
        "## Google Driveにマウントしてマシンスペックを出力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIgX8qtmOOY9",
        "colab_type": "code",
        "outputId": "5d75c25f-1e29-4673-f844-95857cd87251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi > '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/driver/nvidia/gpus/0000:00:04.0/information >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /etc/issue >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/cpuinfo >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5whB14f2LCXO",
        "colab_type": "code",
        "outputId": "ab510864-abe6-4a93-c334-641170a1ddac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Aug 25 15:07 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 25 14:55 ..\n",
            "drwxr-xr-x 1 root root 4096 Aug 22 16:14 .config\n",
            "drwx------ 3 root root 4096 Aug 25 15:07 drive\n",
            "drwxr-xr-x 1 root root 4096 Aug 22 16:14 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45yQPr6Lltrj",
        "colab_type": "text"
      },
      "source": [
        "# Deep CNN (CIFAR-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur3z5pdimJdX",
        "colab_type": "text"
      },
      "source": [
        "## モデルの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CLdMi7Wlzwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58b7833b-0a49-4c91-85b9-b16f6b4bef54"
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input, add\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import Model\n",
        "\n",
        "# this is a part of ResNet and WideResNet.\n",
        "def rescell(data, filters, kernel_size, option=False):\n",
        "    \n",
        "    strides=(1,1)\n",
        "    if option:\n",
        "        strides=(2,2)\n",
        "    \n",
        "    x=Conv2D(filters=filters,\n",
        "\t\t\t kernel_size=kernel_size,\n",
        "\t\t\t strides=strides,\n",
        "\t\t\t padding=\"same\",\n",
        "\t\t\t kernel_initializer='he_normal')(data)\n",
        "    x=BatchNormalization()(x)\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "    # shortcut \n",
        "    data=Conv2D(filters=int(x.shape[3]), \n",
        "\t\t\t\tkernel_size=(1,1), \n",
        "\t\t\t\tstrides=strides, \n",
        "\t\t\t\tpadding=\"same\",\n",
        "\t\t\t\tkernel_initializer='he_normal')(data)\n",
        "\n",
        "    x=Conv2D(filters=filters,\n",
        "\t\t\t kernel_size=kernel_size,\n",
        "\t\t\t strides=(1,1),\n",
        "\t\t\t padding=\"same\",\n",
        "\t\t\t kernel_initializer='he_normal')(x)\n",
        "    x=BatchNormalization()(x)\n",
        "\n",
        "    # connnection\n",
        "    x=add([x,data])\n",
        "\n",
        "    x=Activation('relu')(x)\n",
        "\n",
        "\t\n",
        "    return x\n",
        "\n",
        "def ResNet34(input_shape, num_classes):\n",
        "\tinput=Input(shape=input_shape)\n",
        "  \n",
        "\tx=Conv2D(32,(7,7), padding=\"same\", activation=\"relu\",kernel_initializer='he_normal')(input)\n",
        "\tx=MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\tx=rescell(x,64,(3,3))\n",
        "\n",
        "\tx=rescell(x,128,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\tx=rescell(x,128,(3,3))\n",
        "\n",
        "\tx=rescell(x,256,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\tx=rescell(x,256,(3,3))\n",
        "\n",
        "\tx=rescell(x,512,(3,3),True)\n",
        "\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\tx=rescell(x,512,(3,3))\n",
        "\n",
        "\tx=AveragePooling2D(pool_size=(int(x.shape[1]),int(x.shape[2])),strides=(2,2))(x)\n",
        "\n",
        "\tx=Flatten()(x)\n",
        "\tx=Dense(units=num_classes,kernel_initializer=\"he_normal\",activation=\"softmax\")(x)\n",
        "\tmodel=Model(inputs=input,outputs=[x])\n",
        "  \n",
        "\treturn model"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygmn8vNImOV-",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10 データセットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JELm-0dimTvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "class CIFAR10Dataset():\n",
        "\tdef __init__(self):\n",
        "\t\tself.image_shape = (32, 32, 3)\n",
        "\t\tself.num_classes = 10\n",
        "\t\t\n",
        "\tdef preprocess(self, data, label_data=False):\n",
        "\t\tif label_data:\n",
        "\t\t\t# conver class number to one-hot vector\n",
        "\t\t\tdata = keras.utils.to_categorical(data, self.num_classes)\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\tdata = data.astype(\"float32\")\n",
        "\t\t\tdata /= 255 #convert the value to 0 ~ 1 scale\n",
        "\t\t\tshape = (data.shape[0],) + self.image_shape\n",
        "\t\t\tdata = data.reshape(shape)\n",
        "\t\t\t\n",
        "\t\treturn data\n",
        "\t\n",
        "\tdef get_batch(self):\n",
        "\t\t# x: data, y: lebel\n",
        "\t\t(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\t\t\n",
        "\t\tx_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
        "\t\ty_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
        "\t\t\t\t\t [y_train, y_test]]\n",
        "\t\t\n",
        "\t\treturn x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pawbuqkSPkg",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard用のログファイル生成関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEgHJML0SZdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "from keras.callbacks import TensorBoard\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtlErnk9tL4z",
        "colab_type": "text"
      },
      "source": [
        "## ImageDataGeneratorクラスの拡張\n",
        "random crop\n",
        "mix up\n",
        "cutout\n",
        "を実装する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMROWCFSmE5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class ImageDataGeneratorEX(ImageDataGenerator):\n",
        "\tdef __init__(self,\n",
        "               featurewise_center=False,\n",
        "               samplewise_center=False, \n",
        "               featurewise_std_normalization=False,\n",
        "               samplewise_std_normalization=False,\n",
        "               zca_whitening=False,\n",
        "               zca_epsilon=1e-06,\n",
        "               rotation_range=0.0,\n",
        "               width_shift_range=0.0,\n",
        "               height_shift_range=0.0,\n",
        "               brightness_range=None,\n",
        "               shear_range=0.0,\n",
        "               zoom_range=0.0, \n",
        "               channel_shift_range=0.0,\n",
        "               fill_mode='nearest',\n",
        "               cval=0.0,\n",
        "               horizontal_flip=False, \n",
        "               vertical_flip=False,\n",
        "               rescale=None,\n",
        "               preprocessing_function=None,\n",
        "               data_format=None,\n",
        "               validation_split=0.0, \n",
        "               random_crop=None,    # a new parameter for random crop\n",
        "               mix_up_alpha=0.0,    # a new parameter for mix up\n",
        "               cutout_mask_size=0   # a new parameter for cutout\n",
        "              ):\n",
        "    \n",
        "\t\t# 親クラスのコンストラクタ\n",
        "\t\tsuper().__init__(featurewise_center, samplewise_center, featurewise_std_normalization, samplewise_std_normalization, zca_whitening, zca_epsilon, rotation_range, width_shift_range, height_shift_range, brightness_range, shear_range, zoom_range, channel_shift_range, fill_mode, cval, horizontal_flip, vertical_flip, rescale, preprocessing_function, data_format, validation_split)\n",
        "\t\t# 拡張処理のパラメーター\n",
        "\t\t # Mix-up\n",
        "\t\tassert mix_up_alpha >= 0.0\n",
        "\t\tself.mix_up_alpha = mix_up_alpha\n",
        "\t\t# Random Crop\n",
        "\t\tassert random_crop == None or len(random_crop) == 2\n",
        "\t\tself.random_crop_size = random_crop\n",
        "\t\tself.cutout_mask_size = cutout_mask_size\n",
        "    \n",
        "\t# ランダムクロップ\n",
        "    # 参考 https://jkjung-avt.github.io/keras-image-cropping/\n",
        "\tdef random_crop(self, original_img):\n",
        "        # Note: image_data_format is 'channel_last'\n",
        "\t\tassert original_img.shape[2] == 3\n",
        "\t\tif original_img.shape[0] < self.random_crop_size[0] or original_img.shape[1] < self.random_crop_size[1]:\n",
        "\t\t\traise ValueError(f\"Invalid random_crop_size : original = {original_img.shape}, crop_size = {self.random_crop_size}\")\n",
        "\t\theight, width = original_img.shape[0], original_img.shape[1]\n",
        "\t\tdy, dx = self.random_crop_size\n",
        "\t\tx = np.random.randint(0, width - dx + 1)\n",
        "\t\ty = np.random.randint(0, height - dy + 1)\n",
        "\t\treturn original_img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "    # Mix-up\n",
        "    # 参考 https://qiita.com/yu4u/items/70aa007346ec73b7ff05\n",
        "\tdef mix_up(self, X1, y1, X2, y2):\n",
        "\t\tassert X1.shape[0] == y1.shape[0] == X2.shape[0] == y2.shape[0]\n",
        "\t\tbatch_size = X1.shape[0]\n",
        "\t\tl = np.random.beta(self.mix_up_alpha, self.mix_up_alpha, batch_size)\n",
        "\t\tX_l = l.reshape(batch_size, 1, 1, 1)\n",
        "\t\ty_l = l.reshape(batch_size, 1)\n",
        "\t\tX = X1 * X_l + X2 * (1-X_l)\n",
        "\t\ty = y1 * y_l + y2 * (1-y_l)\n",
        "\t\treturn X, y\n",
        "    \n",
        "\tdef cutout(self, x, y):\n",
        "\t\treturn np.array(list(map(self._cutout, x))), y\n",
        "\n",
        "\tdef _cutout(self, image_origin):\n",
        "\t\t# 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
        "\t\timg = np.copy(image_origin)\n",
        "\t\tmask_value = img.mean()\n",
        "\t\t# 乱数固定(flowでseed固定したら必要ないかも)\n",
        "\n",
        "\t\th, w, _ = img.shape\n",
        "\t\t# マスクをかける場所のtop, leftをランダムに決める\n",
        "\t\t# はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
        "\t\ttop = np.random.randint(0 - self.cutout_mask_size // 2, h - self.cutout_mask_size)\n",
        "\t\tleft = np.random.randint(0 - self.cutout_mask_size // 2, w - self.cutout_mask_size)\n",
        "\t\tbottom = top + self.cutout_mask_size\n",
        "\t\tright = left + self.cutout_mask_size\n",
        "\n",
        "\t\t# はみ出した場合の処理\n",
        "\t\tif top < 0:\n",
        "\t\t\ttop = 0\n",
        "\t\tif left < 0:\n",
        "\t\t\tleft = 0\n",
        "\n",
        "\t\t# マスク部分の画素値を平均値で埋める\n",
        "\t\timg[top:bottom, left:right, :].fill(mask_value)\n",
        "\t\treturn img\n",
        "\n",
        "\n",
        "\tdef flow(self, \n",
        "\t\t\t x, y=None, \n",
        "\t\t\t batch_size=32, \n",
        "\t\t\t shuffle=True,\n",
        "\t\t\t sample_weight=None,\n",
        "\t\t\t seed=None, \n",
        "\t\t\t save_to_dir=None, \n",
        "\t\t\t save_prefix='', \n",
        "\t\t\t save_format='png', \n",
        "\t\t\t subset=None\n",
        "\t\t):\n",
        "\t\t\n",
        "\t\tbatches = super().flow(x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\n",
        "\t\t# 拡張処理\n",
        "\t\twhile True:\n",
        "\t\t\tbatch_x, batch_y = next(batches)\n",
        "\t\t\t\n",
        "\t\t\t# mix up\n",
        "\t\t\tif self.mix_up_alpha > 0:\n",
        "\t\t\t\twhile True:\n",
        "\t\t\t\t\tbatch_x_2, batch_y_2 = next(batches)\n",
        "\t\t\t\t\tm1, m2 = batch_x.shape[0], batch_x_2.shape[0]\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif m1 < m2:\n",
        "\t\t\t\t\t\tbatch_x_2 = batch_x_2[:m1]\n",
        "\t\t\t\t\t\tbatch_y_2 = batch_y_2[:m1]\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\telif m1 == m2:\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\tbatch_x, batch_y = self.mix_up(batch_x, batch_y, batch_x_2, batch_y_2)\n",
        "\t\t\t\n",
        "\t\t\t# Random crop\n",
        "\t\t\tif self.random_crop_size is not None:\n",
        "\t\t\t\tx = np.zeros((batch_x.shape[0], self.random_crop_size[0], self.random_crop_size[1], 3))\n",
        "\t\t\t\tfor i in range(batch_x.shape[0]):\n",
        "\t\t\t\t\tx[i] = self.random_crop(batch_x[i])\n",
        "\t\t\t\tbatch_x = x\n",
        "\t\t\t\n",
        "\t\t\tif self.cutout_mask_size > 0:\n",
        "\t\t\t\tbatch_x, batch_y = self.cutout(batch_x, batch_y)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tyield (batch_x, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TWZvmmxmsK2",
        "colab_type": "text"
      },
      "source": [
        "## Training, Evaluation用クラスの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxj9ZLVbmqnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import RMSprop, Adam, Nadam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard\n",
        "\n",
        "class Trainer():\n",
        "\t\n",
        "\tdef __init__(self, model, loss, optimizer, logdir = './'):\n",
        "\t\tself._target = model\n",
        "\t\tself._target.compile(\n",
        "\t\t\t\tloss=loss, optimizer=optimizer, metrics=[\"accuracy\"]\n",
        "\t\t\t\t)\n",
        "\t\tself.verbose = 1 # visualize progress bar: 0(OFF), 1(On), 2(On:each data) \n",
        "\t\t#self.log_dir = os.path.join(os.path.dirname(__file__), logdir)\n",
        "\t\tself.log_dir = os.path.join(logdir)\n",
        "\t\tself.model_file_name = \"model_file.hdf5\"\n",
        "\t\n",
        "\tdef train_for_tuning_test_data(self, \n",
        "            x_train, y_train, x_test, y_test, batch_size, epochs, lr_scheduler):\n",
        "\t\tdatagen = ImageDataGeneratorEX(\n",
        "\t\t\t      featurewise_center=False,            # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,             # set each sample mean to 0\n",
        "            featurewise_std_normalization=False, # divide inputs by std\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,                 # apply ZCA whitening\n",
        "            rotation_range=20,                   # randomly rotate images in the range (0~180)\n",
        "            width_shift_range=0.2,               # randomly shift images horizontally\n",
        "            height_shift_range=0.2,              # randomly shift images vertically\n",
        "            zoom_range = 0.2,\n",
        "            channel_shift_range = 0.2,\n",
        "            horizontal_flip=True,                # randomly flip images\n",
        "            vertical_flip=False,                 # randomly flip images\n",
        "            random_crop=None,\n",
        "\t\t\t      mix_up_alpha=0.0,\n",
        "\t\t\t      cutout_mask_size=0\n",
        "\t\t)\n",
        "        \n",
        "    # training (validation dataはデータ拡張はしない)\n",
        "\t\tmodel_path = os.path.join(self.log_dir, self.model_file_name)\n",
        "\t\tself._target.fit_generator(\n",
        "            generator        = datagen.flow(x_train,y_train, batch_size,seed=0),\n",
        "            steps_per_epoch  = x_train.shape[0] // batch_size,\n",
        "            epochs           = epochs,\n",
        "            validation_data  = ImageDataGenerator().flow(x_test,y_test, batch_size),\n",
        "\t\t\t      validation_steps = x_test.shape[0] // batch_size,\n",
        "            callbacks=[\n",
        "                LearningRateScheduler(lr_scheduler),\n",
        "                make_tensorboard(set_dir_name=self.log_dir),\n",
        "                ModelCheckpoint(model_path, save_best_only=True,monitor='val_acc',mode='max')\n",
        "            ],\n",
        "            verbose = self.verbose,\n",
        "            use_multiprocessing=True,\n",
        "            #workers = 4\n",
        "        )\n",
        "\t\t\n",
        "\n",
        "class Evaluator():\n",
        "    \n",
        "    def __init__(self, result_file_path=\"./prediction_result.csv\"):\n",
        "        self.result_file_path=\"./prediction_result.csv\"\n",
        "        \n",
        "    def simple_evaluate(self, model, x_test, label):\n",
        "        print(\"start evaluation...\")\n",
        "        score = model.evaluate(x_test, y_test, verbose=1)\n",
        "        print(\"Test loss:\", score[0])\n",
        "        print(\"Test accuracy:\", score[1])\n",
        "        return score\n",
        "    \n",
        "    def tta_evaluate(self, model, x_test, label, batch_size = 2500, tta_epochs = 2):\n",
        "        print(\"batch size (TTA): \"+str(batch_size))\n",
        "        print(\"epochs (TTA): \"+str(tta_epochs))\n",
        "        tta = TTA()\n",
        "        tta_pred = tta.predict(model, x_test, batch_size, epochs = tta_epochs)\n",
        "        print(\"Test accuracy(TTA): \",end = \"\")\n",
        "        print( accuracy_score( np.argmax(tta_pred,axis = 1) , np.argmax(label,axis = 1)))\n",
        "        return tta_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCiJEpaB-HAv",
        "colab_type": "text"
      },
      "source": [
        "## 学習率減衰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4me_PZO-F2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_schedule_for_Adam(epoch):\n",
        "\tlr = 0.001\n",
        "\tif(epoch >= 200): lr = 0.0002 \n",
        "\tif(epoch >= 275): lr = 0.00002\n",
        "\treturn lr\n",
        "\n",
        "def learning_rate_schedule_for_SGD(epoch):\n",
        "\tlr = 0.1\n",
        "\tif(epoch >= 100): lr = 0.01 \n",
        "\tif(epoch >= 200): lr = 0.001\n",
        "\treturn lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKULnAcX2ilW",
        "colab_type": "text"
      },
      "source": [
        "## 実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzvig0oHnqoY",
        "colab_type": "code",
        "outputId": "a89ff499-0d16-4262-ae2b-1649390e30ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = CIFAR10Dataset()\n",
        "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
        "\n",
        "\n",
        "save_dir='/content/drive/My Drive/Colab Notebooks/Logs/ResNet_1/'\n",
        "\n",
        "# create model\n",
        "model = ResNet34(dataset.image_shape, dataset.num_classes)\n",
        "\n",
        "#model = load_model(save_dir+'model_file.hdf5')\n",
        "model.summary()\n",
        "\n",
        "# train the model\n",
        "#trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=SGD(lr=0.1, momentum=0.9, decay=0.0005, nesterov=True), logdir=save_dir)\n",
        "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=Adam(), logdir=save_dir)\n",
        "trainer.train_for_tuning_test_data(\n",
        "            x_train, y_train, x_test, y_test, batch_size=128, epochs=300, \n",
        "            lr_scheduler=learning_rate_schedule_for_Adam)\n",
        "\n",
        "\n",
        "# bestなモデルをロードする\n",
        "model = load_model(save_dir+trainer.model_file_name)\n",
        "#model = load_model(save_dir+\"cnn_best_acc_model.hdf5\")\n",
        "\n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.simple_evaluate(model, x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0825 15:07:55.736677 139793094752128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mywGzeIugMUf",
        "colab_type": "text"
      },
      "source": [
        "##  Test Time Augmentation（TTA）を用いた推論 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkHjWCv1gLi6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "class TTA:\n",
        "    \n",
        "    #test_time_augmentation\n",
        "    #batch_sizeは，test_sizeの約数!!!\n",
        "    def predict(self, model, x_test, batch_size ,epochs = 10):\n",
        "        \n",
        "        # Augmentation用generatorによるデータセットの作成\n",
        "        data_flow = self.generator(x_test, batch_size)\n",
        "        \n",
        "        test_size = x_test.shape[0]\n",
        "        pred = np.zeros(shape = (test_size,10), dtype = float)\n",
        "        \n",
        "        step_per_epoch = test_size //batch_size\n",
        "        for epoch in range(epochs):\n",
        "            print( 'epoch: ' + str(epoch+1)+'/'+str(epochs))\n",
        "            for step in range(step_per_epoch):\n",
        "                #print( 'step: ' + str(step+1)+'/'+str(step_per_epoch))\n",
        "                sta = batch_size * step\n",
        "                end = sta + batch_size\n",
        "                tmp_x = data_flow.__next__()\n",
        "                pred[sta:end] += model.predict(tmp_x)        \n",
        "        return pred / epochs\n",
        "    \n",
        "    \n",
        "    def generator(self, x_test,batch_size):\n",
        "        return ImageDataGeneratorEX(\n",
        "                    rotation_range = 10,\n",
        "                    horizontal_flip = True,\n",
        "                    height_shift_range = 0.1,\n",
        "                    width_shift_range = 0.1,\n",
        "                    zoom_range = 0.1,\n",
        "                    channel_shift_range = 0.1,\n",
        "            \t\t\t  #random_crop=None,\n",
        "\t\t\t              #mix_up_alpha=0.2,\n",
        "\t\t\t              #cutout_mask_size=16\n",
        "                ).flow(x_test,batch_size = batch_size,shuffle = False, seed=756) #756 9447\n",
        "\n",
        "      \n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.tta_evaluate(model, x_test, y_test, batch_size = 500, tta_epochs = 50)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}