{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_cnn_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oxygen0605/ImageClassification/blob/master/deep_cnn_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj4ebRdWOMpm",
        "colab_type": "text"
      },
      "source": [
        "# Google Colaboratory環境の初期設定\n",
        "\n",
        "## Google Driveにマウントしてマシンスペックを出力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIgX8qtmOOY9",
        "colab_type": "code",
        "outputId": "cfa90cb2-53a1-4a93-a4f9-2691f2d930ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi > '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/driver/nvidia/gpus/0000:00:04.0/information >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /etc/issue >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/cpuinfo >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5whB14f2LCXO",
        "colab_type": "code",
        "outputId": "61c359b8-24ab-43ab-97e5-8735e6620918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Aug 19 15:51 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 19 15:47 ..\n",
            "drwxr-xr-x 1 root root 4096 Aug 13 16:04 .config\n",
            "drwx------ 3 root root 4096 Aug 19 15:51 drive\n",
            "drwxr-xr-x 1 root root 4096 Aug  2 16:06 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45yQPr6Lltrj",
        "colab_type": "text"
      },
      "source": [
        "# Deep CNN (CIFAR-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur3z5pdimJdX",
        "colab_type": "text"
      },
      "source": [
        "## モデルの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CLdMi7Wlzwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Dense, BatchNormalization\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import regularizers\n",
        "\n",
        "def deep_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape = input_shape)\n",
        "    \n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(inputs)\n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(512,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(512,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Dense(1024,activation = \"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024,activation = \"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    y  = Dense(num_classes, activation = \"softmax\")(x)\n",
        "\n",
        "    return Model(input = inputs, output = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygmn8vNImOV-",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10 データセットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JELm-0dimTvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "class CIFAR10Dataset():\n",
        "\tdef __init__(self):\n",
        "\t\tself.image_shape = (32, 32, 3)\n",
        "\t\tself.num_classes = 10\n",
        "\t\t\n",
        "\tdef preprocess(self, data, label_data=False):\n",
        "\t\tif label_data:\n",
        "\t\t\t# conver class number to one-hot vector\n",
        "\t\t\tdata = keras.utils.to_categorical(data, self.num_classes)\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\tdata = data.astype(\"float32\")\n",
        "\t\t\tdata /= 255 #convert the value to 0 ~ 1 scale\n",
        "\t\t\tshape = (data.shape[0],) + self.image_shape\n",
        "\t\t\tdata = data.reshape(shape)\n",
        "\t\t\t\n",
        "\t\treturn data\n",
        "\t\n",
        "\tdef get_batch(self):\n",
        "\t\t# x: data, y: lebel\n",
        "\t\t(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\t\t\n",
        "\t\tx_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
        "\t\ty_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
        "\t\t\t\t\t [y_train, y_test]]\n",
        "\t\t\n",
        "\t\treturn x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pawbuqkSPkg",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard用のログファイル生成関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEgHJML0SZdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "from keras.callbacks import TensorBoard\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtlErnk9tL4z",
        "colab_type": "text"
      },
      "source": [
        "## ImageDataGeneratorクラスの拡張\n",
        "random crop\n",
        "mix up\n",
        "cutout\n",
        "を実装する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMROWCFSmE5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class ImageDataGeneratorEX(ImageDataGenerator):\n",
        "  def __init__(self,\n",
        "               featurewise_center = False,\n",
        "               samplewise_center = False, \n",
        "               featurewise_std_normalization = False,\n",
        "               samplewise_std_normalization = False, \n",
        "               zca_whitening = False, \n",
        "               zca_epsilon = 1e-06, \n",
        "               rotation_range = 0.0, \n",
        "               width_shift_range = 0.0, \n",
        "               height_shift_range = 0.0,\n",
        "               brightness_range = None,\n",
        "               shear_range = 0.0,\n",
        "               zoom_range = 0.0, \n",
        "               channel_shift_range = 0.0,\n",
        "               fill_mode = 'nearest',\n",
        "               cval = 0.0,\n",
        "               horizontal_flip = False, \n",
        "               vertical_flip = False,\n",
        "               rescale = None,\n",
        "               preprocessing_function = None,\n",
        "               data_format = None,\n",
        "               validation_split = 0.0, \n",
        "               random_crop = None,\n",
        "               mix_up_alpha = 0.0,\n",
        "               cutout_mask_size = 0\n",
        "              ):\n",
        "    \n",
        "    # 親クラスのコンストラクタ\n",
        "    super().__init__(featurewise_center, samplewise_center, featurewise_std_normalization, samplewise_std_normalization, zca_whitening, zca_epsilon, rotation_range, width_shift_range, height_shift_range, brightness_range, shear_range, zoom_range, channel_shift_range, fill_mode, cval, horizontal_flip, vertical_flip, rescale, preprocessing_function, data_format, validation_split)\n",
        "    # 拡張処理のパラメーター\n",
        "    # Mix-up\n",
        "    assert mix_up_alpha >= 0.0\n",
        "    self.mix_up_alpha = mix_up_alpha\n",
        "    # Random Crop\n",
        "    assert random_crop == None or len(random_crop) == 2\n",
        "    self.random_crop_size = random_crop\n",
        "    \n",
        "    # ランダムクロップ\n",
        "    # 参考 https://jkjung-avt.github.io/keras-image-cropping/\n",
        "    def random_crop(self, original_img):\n",
        "        # Note: image_data_format is 'channel_last'\n",
        "        assert original_img.shape[2] == 3\n",
        "        if original_img.shape[0] < self.random_crop_size[0] or original_img.shape[1] < self.random_crop_size[1]:\n",
        "            raise ValueError(f\"Invalid random_crop_size : original = {original_img.shape}, crop_size = {self.random_crop_size}\")\n",
        "\n",
        "        height, width = original_img.shape[0], original_img.shape[1]\n",
        "        dy, dx = self.random_crop_size\n",
        "        x = np.random.randint(0, width - dx + 1)\n",
        "        y = np.random.randint(0, height - dy + 1)\n",
        "        return original_img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "    # Mix-up\n",
        "    # 参考 https://qiita.com/yu4u/items/70aa007346ec73b7ff05\n",
        "    def mix_up(self, X1, y1, X2, y2):\n",
        "        assert X1.shape[0] == y1.shape[0] == X2.shape[0] == y2.shape[0]\n",
        "        batch_size = X1.shape[0]\n",
        "        l = np.random.beta(self.mix_up_alpha, self.mix_up_alpha, batch_size)\n",
        "        X_l = l.reshape(batch_size, 1, 1, 1)\n",
        "        y_l = l.reshape(batch_size, 1)\n",
        "        X = X1 * X_l + X2 * (1-X_l)\n",
        "        y = y1 * y_l + y2 * (1-y_l)\n",
        "        return X, y\n",
        "    \n",
        "    def cutout(self, x, y, seed=None):\n",
        "        return np.array(list(map(self._cutout, x, seed))), y\n",
        "\n",
        "    def _cutout(self, image_origin, seed=None):\n",
        "        # 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
        "        image = np.copy(image_origin)\n",
        "        mask_value = image.mean()\n",
        "        \n",
        "        # 乱数固定(flowでseed固定したら必要ないかも)\n",
        "        if seed:\n",
        "          np.random.seed(seed)\n",
        "          \n",
        "        h, w, _ = image.shape\n",
        "        # マスクをかける場所のtop, leftをランダムに決める\n",
        "        # はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
        "        top = np.random.randint(0 - self.cutout_mask_size // 2, h - self.cutout_mask_size)\n",
        "        left = np.random.randint(0 - self.cutout_mask_size // 2, w - self.cutout_mask_size)\n",
        "        bottom = top + self.cutout_mask_size\n",
        "        right = left + self.cutout_mask_size\n",
        "\n",
        "        # はみ出した場合の処理\n",
        "        if top < 0:\n",
        "            top = 0\n",
        "        if left < 0:\n",
        "            left = 0\n",
        "\n",
        "        # マスク部分の画素値を平均値で埋める\n",
        "        image[top:bottom, left:right, :].fill(mask_value)\n",
        "        return image\n",
        "\n",
        "    def flow(self, *args, **kwargs):\n",
        "        batches = super().flow(*args, **kwargs)\n",
        "\n",
        "        # 拡張処理\n",
        "        while True:\n",
        "            batch_x, batch_y = next(batches)\n",
        "\n",
        "            if self.cutout_mask_size > 0:\n",
        "                result = self.cutout(batch_x, batch_y)\n",
        "                batch_x, batch_y = result                        \n",
        "\n",
        "            yield (batch_x, batch_y)\n",
        "            \n",
        "ex_gen = ImageDataGeneratorEX(rotation_range=10, horizontal_flip=True, zoom_range=0.1, cutout_mask_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TWZvmmxmsK2",
        "colab_type": "text"
      },
      "source": [
        "## Training, Evaluation用クラスの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxj9ZLVbmqnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import RMSprop, Adam, Nadam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard\n",
        "\n",
        "class Trainer():\n",
        "\t\n",
        "\tdef __init__(self, model, loss, optimizer, logdir = './'):\n",
        "\t\tself._target = model\n",
        "\t\tself._target.compile(\n",
        "\t\t\t\tloss=loss, optimizer=optimizer, metrics=[\"accuracy\"]\n",
        "\t\t\t\t)\n",
        "\t\tself.verbose = 1 # visualize progress bar: 0(OFF), 1(On), 2(On:each data) \n",
        "\t\t#self.log_dir = os.path.join(os.path.dirname(__file__), logdir)\n",
        "\t\tself.log_dir = os.path.join(logdir)\n",
        "\t\tself.model_file_name = \"model_file.hdf5\"\n",
        "\t\n",
        "\tdef train_for_tuning_test_data(self, \n",
        "            x_train, y_train, x_test, y_test, batch_size, epochs, lr_scheduler):\n",
        "\t\tdatagen = ImageDataGenerator(\n",
        "\t\t\tfeaturewise_center=False,            # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,             # set each sample mean to 0\n",
        "            featurewise_std_normalization=False, # divide inputs by std\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,                 # apply ZCA whitening\n",
        "            rotation_range=20,                   # randomly rotate images in the range (0~180)\n",
        "            width_shift_range=0.2,               # randomly shift images horizontally\n",
        "            height_shift_range=0.2,              # randomly shift images vertically\n",
        "            zoom_range = 0.2,\n",
        "            channel_shift_range = 0.2,\n",
        "            horizontal_flip=True,                # randomly flip images\n",
        "            vertical_flip=False                  # randomly flip images\n",
        "\t\t)\n",
        "        \n",
        "    # training (validation dataはデータ拡張はしない)\n",
        "\t\tmodel_path = os.path.join(self.log_dir, self.model_file_name)\n",
        "\t\tself._target.fit_generator(\n",
        "            generator        = datagen.flow(x_train,y_train, batch_size),\n",
        "            steps_per_epoch  = x_train.shape[0] // batch_size,\n",
        "            epochs           = epochs,\n",
        "            validation_data  = ImageDataGenerator().flow(x_test,y_test, batch_size),\n",
        "\t\t\t      validation_steps = x_test.shape[0] // batch_size,\n",
        "            callbacks=[\n",
        "                LearningRateScheduler(lr_scheduler),\n",
        "                make_tensorboard(set_dir_name=self.log_dir),\n",
        "                ModelCheckpoint(model_path, save_best_only=True,monitor='val_acc',mode='max')\n",
        "            ],\n",
        "            verbose = self.verbose,\n",
        "            workers = 4\n",
        "        )\n",
        "\t\t\n",
        "\n",
        "class Evaluator():\n",
        "    \n",
        "    def __init__(self, result_file_path=\"./prediction_result.csv\"):\n",
        "        self.result_file_path=\"./prediction_result.csv\"\n",
        "        \n",
        "    def simple_evaluate(self, model, x_test, label):\n",
        "        print(\"start evaluation...\")\n",
        "        score = model.evaluate(x_test, y_test, verbose=1)\n",
        "        print(\"Test loss:\", score[0])\n",
        "        print(\"Test accuracy:\", score[1])\n",
        "        return score\n",
        "    \n",
        "    def tta_evaluate(self, model, x_test, label, batch_size = 2500, tta_epochs = 2):\n",
        "        print(\"batch size (TTA): \"+str(batch_size))\n",
        "        print(\"epochs (TTA): \"+str(tta_epochs))\n",
        "        tta = TTA()\n",
        "        tta_pred = tta.predict(model, x_test, batch_size, epochs = tta_epochs)\n",
        "        print(\"Test accuracy(TTA): \",end = \"\")\n",
        "        print( accuracy_score( np.argmax(tta_pred,axis = 1) , np.argmax(label,axis = 1)))\n",
        "        return tta_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCiJEpaB-HAv",
        "colab_type": "text"
      },
      "source": [
        "## 学習率減衰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4me_PZO-F2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_schedule_for_Adam(epoch):\n",
        "\tlr = 0.001\n",
        "\tif(epoch >= 100): lr = 0.0002 \n",
        "\tif(epoch >= 200): lr = 0.0001\n",
        "\treturn lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKULnAcX2ilW",
        "colab_type": "text"
      },
      "source": [
        "## 実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzvig0oHnqoY",
        "colab_type": "code",
        "outputId": "3ee25166-a4a2-44d6-d09c-1910ffcaca30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = CIFAR10Dataset()\n",
        "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
        "\n",
        "# create model\n",
        "model = deep_cnn(dataset.image_shape, dataset.num_classes)\n",
        "\n",
        "save_dir='/content/drive/My Drive/Colab Notebooks/Logs/deep_cnn_2/'\n",
        "\n",
        "# train the model\n",
        "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=Adam(), logdir=save_dir)\n",
        "#trainer.train_for_tuning_test_data(\n",
        "#            x_train, y_train, x_test, y_test, batch_size=500, epochs=250, \n",
        "#            lr_scheduler=learning_rate_schedule_for_Adam)\n",
        "\n",
        "\n",
        "# bestなモデルをロードする\n",
        "#model = load_model(save_dir+trainer.model_file_name)\n",
        "model = load_model(save_dir+\"cnn_best_acc_model.hdf5\")\n",
        "\n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.simple_evaluate(model, x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0819 15:52:01.857453 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0819 15:52:01.891460 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0819 15:52:01.899355 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0819 15:52:01.948158 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0819 15:52:01.949096 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0819 15:52:04.743854 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0819 15:52:04.823559 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0819 15:52:04.832094 140189237729152 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "W0819 15:52:05.259215 140189237729152 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0819 15:52:07.774424 140189237729152 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "start evaluation...\n",
            "10000/10000 [==============================] - 7s 661us/step\n",
            "Test loss: 0.2690602608136833\n",
            "Test accuracy: 0.934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mywGzeIugMUf",
        "colab_type": "text"
      },
      "source": [
        "##  Test Time Augmentation（TTA）を用いた推論 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkHjWCv1gLi6",
        "colab_type": "code",
        "outputId": "cd58066b-2888-4b77-913e-746aa41d0d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "class TTA:\n",
        "    \n",
        "    #test_time_augmentation\n",
        "    #batch_sizeは，test_sizeの約数!!!\n",
        "    def predict(self, model, x_test, batch_size ,epochs = 10):\n",
        "        \n",
        "        # Augmentation用generatorによるデータセットの作成\n",
        "        data_flow = self.generator(x_test, batch_size)\n",
        "        \n",
        "        test_size = x_test.shape[0]\n",
        "        pred = np.zeros(shape = (test_size,10), dtype = float)\n",
        "        \n",
        "        step_per_epoch = test_size //batch_size\n",
        "        for epoch in range(epochs):\n",
        "            print( 'epoch: ' + str(epoch+1)+'/'+str(epochs))\n",
        "            for step in range(step_per_epoch):\n",
        "                #print( 'step: ' + str(step+1)+'/'+str(step_per_epoch))\n",
        "                sta = batch_size * step\n",
        "                end = sta + batch_size\n",
        "                tmp_x = data_flow.__next__()\n",
        "                pred[sta:end] += model.predict(tmp_x)        \n",
        "        return pred / epochs\n",
        "    \n",
        "    \n",
        "    def generator(self, x_test,batch_size):\n",
        "        return ImageDataGenerator(\n",
        "                    rotation_range = 10,\n",
        "                    horizontal_flip = True,\n",
        "                    height_shift_range = 0.1,\n",
        "                    width_shift_range = 0.1,\n",
        "                    zoom_range = 0.1,\n",
        "                    channel_shift_range = 0.1\n",
        "                ).flow(x_test,batch_size = batch_size,shuffle = False, seed=756) #756 9447\n",
        "\n",
        "      \n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.tta_evaluate(model, x_test, y_test, batch_size = 500, tta_epochs = 50)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size (TTA): 500\n",
            "epochs (TTA): 100\n",
            "epoch: 1/100\n",
            "epoch: 2/100\n",
            "epoch: 3/100\n",
            "epoch: 4/100\n",
            "epoch: 5/100\n",
            "epoch: 6/100\n",
            "epoch: 7/100\n",
            "epoch: 8/100\n",
            "epoch: 9/100\n",
            "epoch: 10/100\n",
            "epoch: 11/100\n",
            "epoch: 12/100\n",
            "epoch: 13/100\n",
            "epoch: 14/100\n",
            "epoch: 15/100\n",
            "epoch: 16/100\n",
            "epoch: 17/100\n",
            "epoch: 18/100\n",
            "epoch: 19/100\n",
            "epoch: 20/100\n",
            "epoch: 21/100\n",
            "epoch: 22/100\n",
            "epoch: 23/100\n",
            "epoch: 24/100\n",
            "epoch: 25/100\n",
            "epoch: 26/100\n",
            "epoch: 27/100\n",
            "epoch: 28/100\n",
            "epoch: 29/100\n",
            "epoch: 30/100\n",
            "epoch: 31/100\n",
            "epoch: 32/100\n",
            "epoch: 33/100\n",
            "epoch: 34/100\n",
            "epoch: 35/100\n",
            "epoch: 36/100\n",
            "epoch: 37/100\n",
            "epoch: 38/100\n",
            "epoch: 39/100\n",
            "epoch: 40/100\n",
            "epoch: 41/100\n",
            "epoch: 42/100\n",
            "epoch: 43/100\n",
            "epoch: 44/100\n",
            "epoch: 45/100\n",
            "epoch: 46/100\n",
            "epoch: 47/100\n",
            "epoch: 48/100\n",
            "epoch: 49/100\n",
            "epoch: 50/100\n",
            "epoch: 51/100\n",
            "epoch: 52/100\n",
            "epoch: 53/100\n",
            "epoch: 54/100\n",
            "epoch: 55/100\n",
            "epoch: 56/100\n",
            "epoch: 57/100\n",
            "epoch: 58/100\n",
            "epoch: 59/100\n",
            "epoch: 60/100\n",
            "epoch: 61/100\n",
            "epoch: 62/100\n",
            "epoch: 63/100\n",
            "epoch: 64/100\n",
            "epoch: 65/100\n",
            "epoch: 66/100\n",
            "epoch: 67/100\n",
            "epoch: 68/100\n",
            "epoch: 69/100\n",
            "epoch: 70/100\n",
            "epoch: 71/100\n",
            "epoch: 72/100\n",
            "epoch: 73/100\n",
            "epoch: 74/100\n",
            "epoch: 75/100\n",
            "epoch: 76/100\n",
            "epoch: 77/100\n",
            "epoch: 78/100\n",
            "epoch: 79/100\n",
            "epoch: 80/100\n",
            "epoch: 81/100\n",
            "epoch: 82/100\n",
            "epoch: 83/100\n",
            "epoch: 84/100\n",
            "epoch: 85/100\n",
            "epoch: 86/100\n",
            "epoch: 87/100\n",
            "epoch: 88/100\n",
            "epoch: 89/100\n",
            "epoch: 90/100\n",
            "epoch: 91/100\n",
            "epoch: 92/100\n",
            "epoch: 93/100\n",
            "epoch: 94/100\n",
            "epoch: 95/100\n",
            "epoch: 96/100\n",
            "epoch: 97/100\n",
            "epoch: 98/100\n",
            "epoch: 99/100\n",
            "epoch: 100/100\n",
            "Test accuracy(TTA): 0.9445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}