{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_cnn_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oxygen0605/ImageClassification/blob/master/deep_cnn_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj4ebRdWOMpm",
        "colab_type": "text"
      },
      "source": [
        "# Google Colaboratory環境の初期設定\n",
        "\n",
        "## Google Driveにマウントしてマシンスペックを出力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIgX8qtmOOY9",
        "colab_type": "code",
        "outputId": "16b66f44-7e0e-4212-d1f4-9c1338a8a4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!nvidia-smi > '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/driver/nvidia/gpus/0000:00:04.0/information >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /etc/issue >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'\n",
        "!cat /proc/cpuinfo >> '/content/drive/My Drive/Colab Notebooks/Logs/machine_spec.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5whB14f2LCXO",
        "colab_type": "code",
        "outputId": "faa44581-1d8e-4be9-84d3-e07221a8a8b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!ls -al"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Aug 21 00:10 .\n",
            "drwxr-xr-x 1 root root 4096 Aug 20 23:57 ..\n",
            "drwxr-xr-x 1 root root 4096 Aug 13 16:04 .config\n",
            "drwx------ 3 root root 4096 Aug 21 00:10 drive\n",
            "drwxr-xr-x 1 root root 4096 Aug  2 16:06 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45yQPr6Lltrj",
        "colab_type": "text"
      },
      "source": [
        "# Deep CNN (CIFAR-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur3z5pdimJdX",
        "colab_type": "text"
      },
      "source": [
        "## モデルの生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CLdMi7Wlzwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Dense, BatchNormalization\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Activation, Flatten\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import regularizers\n",
        "\n",
        "def deep_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape = input_shape)\n",
        "    \n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(inputs)\n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(256,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(512,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = Conv2D(512,(3,3),padding = \"SAME\",activation= \"relu\")(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "    x = Dense(1024,activation = \"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024,activation = \"relu\")(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    y  = Dense(num_classes, activation = \"softmax\")(x)\n",
        "\n",
        "    return Model(input = inputs, output = y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ygmn8vNImOV-",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10 データセットの用意"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JELm-0dimTvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "class CIFAR10Dataset():\n",
        "\tdef __init__(self):\n",
        "\t\tself.image_shape = (32, 32, 3)\n",
        "\t\tself.num_classes = 10\n",
        "\t\t\n",
        "\tdef preprocess(self, data, label_data=False):\n",
        "\t\tif label_data:\n",
        "\t\t\t# conver class number to one-hot vector\n",
        "\t\t\tdata = keras.utils.to_categorical(data, self.num_classes)\n",
        "\t\t\n",
        "\t\telse:\n",
        "\t\t\tdata = data.astype(\"float32\")\n",
        "\t\t\tdata /= 255 #convert the value to 0 ~ 1 scale\n",
        "\t\t\tshape = (data.shape[0],) + self.image_shape\n",
        "\t\t\tdata = data.reshape(shape)\n",
        "\t\t\t\n",
        "\t\treturn data\n",
        "\t\n",
        "\tdef get_batch(self):\n",
        "\t\t# x: data, y: lebel\n",
        "\t\t(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\t\t\n",
        "\t\tx_train, x_test = [self.preprocess(d) for d in [x_train, x_test]]\n",
        "\t\ty_train, y_test = [self.preprocess(d, label_data=True) for d in\n",
        "\t\t\t\t\t [y_train, y_test]]\n",
        "\t\t\n",
        "\t\treturn x_train, y_train, x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pawbuqkSPkg",
        "colab_type": "text"
      },
      "source": [
        "## TensorBoard用のログファイル生成関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEgHJML0SZdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "from keras.callbacks import TensorBoard\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtlErnk9tL4z",
        "colab_type": "text"
      },
      "source": [
        "## ImageDataGeneratorクラスの拡張\n",
        "random crop\n",
        "mix up\n",
        "cutout\n",
        "を実装する。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMROWCFSmE5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "class ImageDataGeneratorEX(ImageDataGenerator):\n",
        "\tdef __init__(self,\n",
        "               featurewise_center=False,\n",
        "               samplewise_center=False, \n",
        "               featurewise_std_normalization=False,\n",
        "               samplewise_std_normalization=False,\n",
        "               zca_whitening=False,\n",
        "               zca_epsilon=1e-06,\n",
        "               rotation_range=0.0,\n",
        "               width_shift_range=0.0,\n",
        "               height_shift_range=0.0,\n",
        "               brightness_range=None,\n",
        "               shear_range=0.0,\n",
        "               zoom_range=0.0, \n",
        "               channel_shift_range=0.0,\n",
        "               fill_mode='nearest',\n",
        "               cval=0.0,\n",
        "               horizontal_flip=False, \n",
        "               vertical_flip=False,\n",
        "               rescale=None,\n",
        "               preprocessing_function=None,\n",
        "               data_format=None,\n",
        "               validation_split=0.0, \n",
        "               random_crop=None,    # a new parameter for random crop\n",
        "               mix_up_alpha=0.0,    # a new parameter for mix up\n",
        "               cutout_mask_size=0   # a new parameter for cutout\n",
        "              ):\n",
        "    \n",
        "\t\t# 親クラスのコンストラクタ\n",
        "\t\tsuper().__init__(featurewise_center, samplewise_center, featurewise_std_normalization, samplewise_std_normalization, zca_whitening, zca_epsilon, rotation_range, width_shift_range, height_shift_range, brightness_range, shear_range, zoom_range, channel_shift_range, fill_mode, cval, horizontal_flip, vertical_flip, rescale, preprocessing_function, data_format, validation_split)\n",
        "\t\t# 拡張処理のパラメーター\n",
        "\t\t # Mix-up\n",
        "\t\tassert mix_up_alpha >= 0.0\n",
        "\t\tself.mix_up_alpha = mix_up_alpha\n",
        "\t\t# Random Crop\n",
        "\t\tassert random_crop == None or len(random_crop) == 2\n",
        "\t\tself.random_crop_size = random_crop\n",
        "\t\tself.cutout_mask_size = cutout_mask_size\n",
        "    \n",
        "\t# ランダムクロップ\n",
        "    # 参考 https://jkjung-avt.github.io/keras-image-cropping/\n",
        "\tdef random_crop(self, original_img):\n",
        "        # Note: image_data_format is 'channel_last'\n",
        "\t\tassert original_img.shape[2] == 3\n",
        "\t\tif original_img.shape[0] < self.random_crop_size[0] or original_img.shape[1] < self.random_crop_size[1]:\n",
        "\t\t\traise ValueError(f\"Invalid random_crop_size : original = {original_img.shape}, crop_size = {self.random_crop_size}\")\n",
        "\t\theight, width = original_img.shape[0], original_img.shape[1]\n",
        "\t\tdy, dx = self.random_crop_size\n",
        "\t\tx = np.random.randint(0, width - dx + 1)\n",
        "\t\ty = np.random.randint(0, height - dy + 1)\n",
        "\t\treturn original_img[y:(y+dy), x:(x+dx), :]\n",
        "\n",
        "    # Mix-up\n",
        "    # 参考 https://qiita.com/yu4u/items/70aa007346ec73b7ff05\n",
        "\tdef mix_up(self, X1, y1, X2, y2):\n",
        "\t\tassert X1.shape[0] == y1.shape[0] == X2.shape[0] == y2.shape[0]\n",
        "\t\tbatch_size = X1.shape[0]\n",
        "\t\tl = np.random.beta(self.mix_up_alpha, self.mix_up_alpha, batch_size)\n",
        "\t\tX_l = l.reshape(batch_size, 1, 1, 1)\n",
        "\t\ty_l = l.reshape(batch_size, 1)\n",
        "\t\tX = X1 * X_l + X2 * (1-X_l)\n",
        "\t\ty = y1 * y_l + y2 * (1-y_l)\n",
        "\t\treturn X, y\n",
        "    \n",
        "\tdef cutout(self, x, y):\n",
        "\t\treturn np.array(list(map(self._cutout, x))), y\n",
        "\n",
        "\tdef _cutout(self, image_origin):\n",
        "\t\t# 最後に使うfill()は元の画像を書き換えるので、コピーしておく\n",
        "\t\timg = np.copy(image_origin)\n",
        "\t\tmask_value = img.mean()\n",
        "\t\t# 乱数固定(flowでseed固定したら必要ないかも)\n",
        "\n",
        "\t\th, w, _ = img.shape\n",
        "\t\t# マスクをかける場所のtop, leftをランダムに決める\n",
        "\t\t# はみ出すことを許すので、0以上ではなく負の値もとる(最大mask_size // 2はみ出す)\n",
        "\t\ttop = np.random.randint(0 - self.cutout_mask_size // 2, h - self.cutout_mask_size)\n",
        "\t\tleft = np.random.randint(0 - self.cutout_mask_size // 2, w - self.cutout_mask_size)\n",
        "\t\tbottom = top + self.cutout_mask_size\n",
        "\t\tright = left + self.cutout_mask_size\n",
        "\n",
        "\t\t# はみ出した場合の処理\n",
        "\t\tif top < 0:\n",
        "\t\t\ttop = 0\n",
        "\t\tif left < 0:\n",
        "\t\t\tleft = 0\n",
        "\n",
        "\t\t# マスク部分の画素値を平均値で埋める\n",
        "\t\timg[top:bottom, left:right, :].fill(mask_value)\n",
        "\t\treturn img\n",
        "\n",
        "\n",
        "\tdef flow(self, \n",
        "\t\t\t x, y=None, \n",
        "\t\t\t batch_size=32, \n",
        "\t\t\t shuffle=True,\n",
        "\t\t\t sample_weight=None,\n",
        "\t\t\t seed=None, \n",
        "\t\t\t save_to_dir=None, \n",
        "\t\t\t save_prefix='', \n",
        "\t\t\t save_format='png', \n",
        "\t\t\t subset=None\n",
        "\t\t):\n",
        "\t\t\n",
        "\t\tbatches = super().flow(x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\n",
        "\t\t# 拡張処理\n",
        "\t\twhile True:\n",
        "\t\t\tbatch_x, batch_y = next(batches)\n",
        "\t\t\t\n",
        "\t\t\t# mix up\n",
        "\t\t\tif self.mix_up_alpha > 0:\n",
        "\t\t\t\twhile True:\n",
        "\t\t\t\t\tbatch_x_2, batch_y_2 = next(batches)\n",
        "\t\t\t\t\tm1, m2 = batch_x.shape[0], batch_x_2.shape[0]\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tif m1 < m2:\n",
        "\t\t\t\t\t\tbatch_x_2 = batch_x_2[:m1]\n",
        "\t\t\t\t\t\tbatch_y_2 = batch_y_2[:m1]\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\telif m1 == m2:\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\tbatch_x, batch_y = self.mix_up(batch_x, batch_y, batch_x_2, batch_y_2)\n",
        "\t\t\t\n",
        "\t\t\t# Random crop\n",
        "\t\t\tif self.random_crop_size is not None:\n",
        "\t\t\t\tx = np.zeros((batch_x.shape[0], self.random_crop_size[0], self.random_crop_size[1], 3))\n",
        "\t\t\t\tfor i in range(batch_x.shape[0]):\n",
        "\t\t\t\t\tx[i] = self.random_crop(batch_x[i])\n",
        "\t\t\t\tbatch_x = x\n",
        "\t\t\t\n",
        "\t\t\tif self.cutout_mask_size > 0:\n",
        "\t\t\t\tbatch_x, batch_y = self.cutout(batch_x, batch_y)\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tyield (batch_x, batch_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TWZvmmxmsK2",
        "colab_type": "text"
      },
      "source": [
        "## Training, Evaluation用クラスの定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxj9ZLVbmqnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
        "from keras.optimizers import RMSprop, Adam, Nadam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import unicode_literals\n",
        "from time import gmtime, strftime\n",
        "import os\n",
        "\n",
        "\n",
        "def make_tensorboard(set_dir_name=''):\n",
        "    tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\", gmtime())\n",
        "    directory_name = tictoc\n",
        "    log_dir = set_dir_name + '_' + directory_name\n",
        "    os.mkdir(log_dir)\n",
        "    tensorboard = TensorBoard(log_dir=log_dir, write_graph=True, )\n",
        "    return tensorboard\n",
        "\n",
        "class Trainer():\n",
        "\t\n",
        "\tdef __init__(self, model, loss, optimizer, logdir = './'):\n",
        "\t\tself._target = model\n",
        "\t\tself._target.compile(\n",
        "\t\t\t\tloss=loss, optimizer=optimizer, metrics=[\"accuracy\"]\n",
        "\t\t\t\t)\n",
        "\t\tself.verbose = 1 # visualize progress bar: 0(OFF), 1(On), 2(On:each data) \n",
        "\t\t#self.log_dir = os.path.join(os.path.dirname(__file__), logdir)\n",
        "\t\tself.log_dir = os.path.join(logdir)\n",
        "\t\tself.model_file_name = \"model_file.hdf5\"\n",
        "\t\n",
        "\tdef train_for_tuning_test_data(self, \n",
        "            x_train, y_train, x_test, y_test, batch_size, epochs, lr_scheduler):\n",
        "\t\tdatagen = ImageDataGeneratorEX(\n",
        "\t\t\t      featurewise_center=False,            # set input mean to 0 over the dataset\n",
        "            samplewise_center=False,             # set each sample mean to 0\n",
        "            featurewise_std_normalization=False, # divide inputs by std\n",
        "            samplewise_std_normalization=False,  # divide each input by its std\n",
        "            zca_whitening=False,                 # apply ZCA whitening\n",
        "            rotation_range=0,                   # randomly rotate images in the range (0~180)\n",
        "            width_shift_range=0.0,               # randomly shift images horizontally\n",
        "            height_shift_range=0.0,              # randomly shift images vertically\n",
        "            zoom_range = 0.0,\n",
        "            channel_shift_range = 0.0,\n",
        "            horizontal_flip=True,                # randomly flip images\n",
        "            vertical_flip=False,                 # randomly flip images\n",
        "            random_crop=None,\n",
        "\t\t\t      mix_up_alpha=0.2, \n",
        "\t\t\t      cutout_mask_size=16\n",
        "\t\t)\n",
        "        \n",
        "    # training (validation dataはデータ拡張はしない)\n",
        "\t\tmodel_path = os.path.join(self.log_dir, self.model_file_name)\n",
        "\t\tself._target.fit_generator(\n",
        "            generator        = datagen.flow(x_train,y_train, batch_size,seed=0),\n",
        "            steps_per_epoch  = x_train.shape[0] // batch_size,\n",
        "            epochs           = epochs,\n",
        "            validation_data  = ImageDataGenerator().flow(x_test,y_test, batch_size),\n",
        "\t\t\t      validation_steps = x_test.shape[0] // batch_size,\n",
        "            callbacks=[\n",
        "                LearningRateScheduler(lr_scheduler),\n",
        "                make_tensorboard(set_dir_name=self.log_dir),\n",
        "                ModelCheckpoint(model_path, save_best_only=True,monitor='val_acc',mode='max')\n",
        "            ],\n",
        "            verbose = self.verbose,\n",
        "            use_multiprocessing=True,\n",
        "            #workers = 4\n",
        "        )\n",
        "\t\t\n",
        "\n",
        "class Evaluator():\n",
        "    \n",
        "    def __init__(self, result_file_path=\"./prediction_result.csv\"):\n",
        "        self.result_file_path=\"./prediction_result.csv\"\n",
        "        \n",
        "    def simple_evaluate(self, model, x_test, label):\n",
        "        print(\"start evaluation...\")\n",
        "        score = model.evaluate(x_test, y_test, verbose=1)\n",
        "        print(\"Test loss:\", score[0])\n",
        "        print(\"Test accuracy:\", score[1])\n",
        "        return score\n",
        "    \n",
        "    def tta_evaluate(self, model, x_test, label, batch_size = 2500, tta_epochs = 2):\n",
        "        print(\"batch size (TTA): \"+str(batch_size))\n",
        "        print(\"epochs (TTA): \"+str(tta_epochs))\n",
        "        tta = TTA()\n",
        "        tta_pred = tta.predict(model, x_test, batch_size, epochs = tta_epochs)\n",
        "        print(\"Test accuracy(TTA): \",end = \"\")\n",
        "        print( accuracy_score( np.argmax(tta_pred,axis = 1) , np.argmax(label,axis = 1)))\n",
        "        return tta_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCiJEpaB-HAv",
        "colab_type": "text"
      },
      "source": [
        "## 学習率減衰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4me_PZO-F2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def learning_rate_schedule_for_Adam(epoch):\n",
        "\tlr = 0.001\n",
        "\tif(epoch >= 190): lr = 0.0002 \n",
        "\tif(epoch >= 240): lr = 0.0001\n",
        "\treturn lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKULnAcX2ilW",
        "colab_type": "text"
      },
      "source": [
        "## 実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzvig0oHnqoY",
        "colab_type": "code",
        "outputId": "ec8a4738-8655-40e0-df51-e437d35985bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "\n",
        "\n",
        "# create dataset\n",
        "dataset = CIFAR10Dataset()\n",
        "x_train, y_train, x_test, y_test = dataset.get_batch()\n",
        "\n",
        "# create model\n",
        "model = deep_cnn(dataset.image_shape, dataset.num_classes)\n",
        "\n",
        "save_dir='/content/drive/My Drive/Colab Notebooks/Logs/deep_cnn_2/'\n",
        "\n",
        "# train the model\n",
        "trainer = Trainer(model, loss=\"categorical_crossentropy\", optimizer=Adam(), logdir=save_dir)\n",
        "trainer.train_for_tuning_test_data(\n",
        "            x_train, y_train, x_test, y_test, batch_size=500, epochs=250, \n",
        "            lr_scheduler=learning_rate_schedule_for_Adam)\n",
        "\n",
        "\n",
        "# bestなモデルをロードする\n",
        "model = load_model(save_dir+trainer.model_file_name)\n",
        "#model = load_model(save_dir+\"cnn_best_acc_model.hdf5\")\n",
        "\n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.simple_evaluate(model, x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 [==============================] - 63s 627ms/step - loss: 2.0298 - acc: 0.2277 - val_loss: 1.8116 - val_acc: 0.3086\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 1.6994 - acc: 0.3976 - val_loss: 1.8756 - val_acc: 0.3722\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 58s 575ms/step - loss: 1.5160 - acc: 0.4971 - val_loss: 1.5031 - val_acc: 0.4834\n",
            "start evaluation...\n",
            "10000/10000 [==============================] - 8s 798us/step\n",
            "Test loss: 1.5031179822921752\n",
            "Test accuracy: 0.4834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mywGzeIugMUf",
        "colab_type": "text"
      },
      "source": [
        "##  Test Time Augmentation（TTA）を用いた推論 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkHjWCv1gLi6",
        "colab_type": "code",
        "outputId": "7a91bea9-b476-43de-fb38-08afd461889a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "\n",
        "class TTA:\n",
        "    \n",
        "    #test_time_augmentation\n",
        "    #batch_sizeは，test_sizeの約数!!!\n",
        "    def predict(self, model, x_test, batch_size ,epochs = 10):\n",
        "        \n",
        "        # Augmentation用generatorによるデータセットの作成\n",
        "        data_flow = self.generator(x_test, batch_size)\n",
        "        \n",
        "        test_size = x_test.shape[0]\n",
        "        pred = np.zeros(shape = (test_size,10), dtype = float)\n",
        "        \n",
        "        step_per_epoch = test_size //batch_size\n",
        "        for epoch in range(epochs):\n",
        "            print( 'epoch: ' + str(epoch+1)+'/'+str(epochs))\n",
        "            for step in range(step_per_epoch):\n",
        "                #print( 'step: ' + str(step+1)+'/'+str(step_per_epoch))\n",
        "                sta = batch_size * step\n",
        "                end = sta + batch_size\n",
        "                tmp_x = data_flow.__next__()\n",
        "                pred[sta:end] += model.predict(tmp_x)        \n",
        "        return pred / epochs\n",
        "    \n",
        "    \n",
        "    def generator(self, x_test,batch_size):\n",
        "        return ImageDataGeneratorEX(\n",
        "                    rotation_range = 10,\n",
        "                    horizontal_flip = True,\n",
        "                    height_shift_range = 0.1,\n",
        "                    width_shift_range = 0.1,\n",
        "                    zoom_range = 0.1,\n",
        "                    channel_shift_range = 0.1,\n",
        "            \t\t\t  #random_crop=None,\n",
        "\t\t\t              #mix_up_alpha=0.2,\n",
        "\t\t\t              #cutout_mask_size=16\n",
        "                ).flow(x_test,batch_size = batch_size,shuffle = False, seed=756) #756 9447\n",
        "\n",
        "      \n",
        "# show result\n",
        "evaluator = Evaluator()\n",
        "score = evaluator.tta_evaluate(model, x_test, y_test, batch_size = 500, tta_epochs = 50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch size (TTA): 500\n",
            "epochs (TTA): 50\n",
            "epoch: 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-24ac21dbe8e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# show result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtta_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtta_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-e3c40605168a>\u001b[0m in \u001b[0;36mtta_evaluate\u001b[0;34m(self, model, x_test, label, batch_size, tta_epochs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epochs (TTA): \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtta_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mtta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtta_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtta_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy(TTA): \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtta_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-24ac21dbe8e7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x_test, batch_size, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0msta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mtmp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_flow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-10302b0ae969>\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;31m# 拡張処理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                         \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                         \u001b[0;31m# mix up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    }
  ]
}